{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hhdpwdE1z5aU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from submit_2 import my_map\n",
        "# from submit_2 import my_fit\n",
        "from scipy.linalg import khatri_rao\n",
        "import time as tm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_fit( X_train, y_train ):\n",
        "################################\n",
        "#  Non Editable Region Ending  #\n",
        "################################\n",
        "\tfeat = my_map(X_train)\n",
        "\tmodel = LogisticRegression(penalty='l2', C=62.0, fit_intercept=True, max_iter=2500)\n",
        "\t# Use this method to train your model using training CRPs\n",
        "\t# X_train has 32 columns containing the challeenge bits\n",
        "\t# y_train contains the responses\n",
        "\tmodel.fit(feat, y_train)\n",
        "\tw = model.coef_[0]\n",
        "\tb = model.intercept_\n",
        "\t\n",
        "\t# THE RETURNED MODEL SHOULD BE A SINGLE VECTOR AND A BIAS TERM\n",
        "\t# If you do not wish to use a bias term, set it to 0\n",
        "\treturn w, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_map(X):\n",
        "    X = np.hstack((X, np.ones((X.shape[0], 1))))\n",
        "    X = 1 - 2 * X\n",
        "\n",
        "    # Compute the cumulative products\n",
        "    cumprod_X = np.cumprod(X[:, ::-1], axis=1)[:, ::-1]\n",
        "\n",
        "    # Compute the feature interactions directly\n",
        "    feat = np.ones((X.shape[0], X.shape[1] * (X.shape[1] - 1) // 2 + 1))\n",
        "\n",
        "    index = 0\n",
        "    for i in range(X.shape[1]):\n",
        "        for j in range(i + 1, X.shape[1]):\n",
        "            feat[:, index] = cumprod_X[:, i] * cumprod_X[:, j]\n",
        "            index += 1\n",
        "\n",
        "    return feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def my_map__(X):\n",
        "    X_with_ones = np.column_stack((X, np.ones(X.shape[0])))\n",
        "\n",
        "    # Compute 1 - 2 * X using broadcasting\n",
        "    X_transformed = 1 - 2 * X_with_ones\n",
        "\n",
        "    # Compute cumulative products using vectorized operation\n",
        "    cumprod_X = np.flip(np.cumprod(np.flip(X_transformed, axis=1), axis=1), axis=1)\n",
        "\n",
        "    # Compute feature interactions without explicit loops\n",
        "    num_features = X.shape[1]\n",
        "    indices = np.triu_indices(num_features, 1)\n",
        "    feat = np.prod(cumprod_X[:, indices[0]] * cumprod_X[:, indices[1]], axis=2)\n",
        "\n",
        "    # Append a column of ones as the last feature\n",
        "    feat = np.column_stack((feat, np.ones(X.shape[0])))\n",
        "\n",
        "    return feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def my_map(X):\n",
        "# ################################\n",
        "# #  Non Editable Region Ending  #\n",
        "# ################################\n",
        "# \tX = np.hstack((X, np.ones((X.shape[0], 1))))\n",
        "# \tX = 1 - 2 * X\n",
        "# \t# print(X.shape)\n",
        "\t\n",
        "# \tarr = []\n",
        "# \tfor i in range(X.shape[0]):\n",
        "# \t\ttemp = []\n",
        "# \t\ttemp.append(X[i][-1])\n",
        "# \t\tfor j in range(X.shape[1] - 2, -1, -1):\n",
        "# \t\t\ttemp.append(X[i][j] * temp[-1])\n",
        "# \t\ttemp.reverse()\n",
        "# \t\tarr.append(np.array(temp))\n",
        "    \n",
        "# \tarr = np.array(arr)\n",
        "# \t# print(arr.shape)\n",
        "# \tfeat = []\n",
        "# \tfor i in range(X.shape[0]):\n",
        "# \t\tres = []\n",
        "# \t\tfor j in range(X.shape[1]):\n",
        "# \t\t\tfor k in range(j+1, X.shape[1]):\n",
        "# \t\t\t\tres.append(arr[i][j] * arr[i][k])\n",
        "# \t\tfeat.append(np.array(res))\n",
        "\n",
        "# \treturn np.array(feat)\n",
        "\n",
        "# \t# # Use this method to create features.\n",
        "# \t# # It is likely that my_fit will internally call my_map to create features for train points\n",
        "\n",
        "# \t# return feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "x0salcYbPVeY"
      },
      "outputs": [],
      "source": [
        "Z_trn = np.loadtxt( \"dummy/secret_train.dat\" )\n",
        "Z_tst = np.loadtxt( \"dummy/secret_test.dat\" )\n",
        "\n",
        "n_trials = 5\n",
        "\n",
        "bias = 0\n",
        "d_size = 0\n",
        "t_train = 0\n",
        "t_map = 0\n",
        "acc = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 528)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_map( Z_tst[:, :-1] ).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 528)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_map( Z_tst[:, :-1] ).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hwn4Alu6Pz1u"
      },
      "outputs": [],
      "source": [
        "for t in range( n_trials ):\n",
        "\ttic = tm.perf_counter()\n",
        "\tw, b = my_fit( Z_trn[:, :-1], Z_trn[:,-1] )\n",
        "\ttoc = tm.perf_counter()\n",
        "\tt_train += toc - tic\n",
        "\n",
        "\td_size += w.shape[0]\n",
        "\tbias += b\n",
        "\n",
        "\ttic = tm.perf_counter()\n",
        "\tfeat = my_map( Z_tst[:, :-1] )\n",
        "\ttoc = tm.perf_counter()\n",
        "\tt_map += toc - tic\n",
        "\n",
        "\tscores = feat.dot( w ) + b\n",
        "\tpred = np.zeros_like( scores )\n",
        "\tpred[scores > 0] = 1\n",
        "\tacc += np.average( Z_tst[ :, -1 ] == pred )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZVG4OM_PQ1EG"
      },
      "outputs": [],
      "source": [
        "d_size /= n_trials\n",
        "t_train /= n_trials\n",
        "t_map /= n_trials\n",
        "acc /= n_trials\n",
        "bias /= n_trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XJEZypo7pQPE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "528.0 0.6477962165954523 0.025102133199106903 0.9925 [-52.9275518]\n"
          ]
        }
      ],
      "source": [
        "print( d_size, t_train, t_map, acc, bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "528.0 0.3904974831850268 0.025894074782263486 0.8267 [0.]\n"
          ]
        }
      ],
      "source": [
        "print( d_size, t_train, t_map, acc, bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
